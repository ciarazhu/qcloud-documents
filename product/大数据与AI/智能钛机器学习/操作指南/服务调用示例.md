模型服务列表页面显示了当前各个服务的运行状态、占用资源、调用地址以及其他信息。单击【模型调用】，可获得当前服务的访问地址和密钥。
![avatar](https://main.qcloudimg.com/raw/c996367198ed90aa94b22ac43517cc4e.png)
**下文通过示例展示服务调用方式：**
**模型文件：**tensorflow 框架训练的经典深度学习 inception 模型
**模型运行环境：**tfserving 环境
**模型地址：**cos://data-122232422.cos.ap-bejing.myqcloud.com/tfserving/inception/155645133 
**资源配置：**1CPU 核 2G 内存
**扩缩容配置：** CPU 利用率目标60%，内存利用率目标60%；最小实例数为1，最大实例数为5。
**测试图片：**
![avatar](https://main.qcloudimg.com/raw/e6bcf91f8596a1da18f534e3dc6b2d95.png)
**本地测试：**模型默认暴露两个端口：80端口提供 HTTP 服务，9000端口提供 grpc 服务。模型服务的预测访问路径默认为`/v1/models/m:predict`。本地使用 curl 或者其他 rest 测试工具进行测试，这里我们使用 curl 进行测试，将获取的 token 填写为`header: X-Auth-Token`。
![avatar](https://main.qcloudimg.com/raw/1b6f9b94c2764430e8929075fdf560bf.png)
上图例子中的 `image.encode `为训练生成的 inception 模型定义的 JSON 数据格式：`{"instances":[{"b64": 图片 base64 编码}]}`。这里我们使用上面的测试图片进行编码。可以看出模型服务运行正常，正确的对发送的花朵进行了分类。
